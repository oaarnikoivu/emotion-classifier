{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNZlVqZGJ5dWaMGgEEc4Kpk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b4c51af6063f4c4b867b7a713b38772f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d1e43ff4ec8441c5b09f2b97f652106b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_048f57ad1e2541789b83a068165a57b4",
              "IPY_MODEL_2ba4ef0a49d145a4bc810bf5fae01773"
            ]
          }
        },
        "d1e43ff4ec8441c5b09f2b97f652106b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "048f57ad1e2541789b83a068165a57b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_42cc66053ab340c08d3f5bf8e66de995",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7c98f00deba43848260ef642eef5939"
          }
        },
        "2ba4ef0a49d145a4bc810bf5fae01773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3da62a4916c5401f86ce26fce908cf0a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 232k/232k [00:00&lt;00:00, 7.03MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7425d7bafd0453f93eca7d1cfc49fa3"
          }
        },
        "42cc66053ab340c08d3f5bf8e66de995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7c98f00deba43848260ef642eef5939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3da62a4916c5401f86ce26fce908cf0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7425d7bafd0453f93eca7d1cfc49fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6e23166515c464895fa280dd65539b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7e5b6c665247469e8d4112c43680516b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a07f1b4fe8ac42a295316580c93d72a9",
              "IPY_MODEL_5301a0a051d5473b858e8971f444968c"
            ]
          }
        },
        "7e5b6c665247469e8d4112c43680516b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a07f1b4fe8ac42a295316580c93d72a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_59acb0938f52407dada7bb24c2efd584",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8568d678beea41e2aad641b694e5db5a"
          }
        },
        "5301a0a051d5473b858e8971f444968c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_225b67535a4a4792ad5b60baf3d91ef6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 361/361 [00:00&lt;00:00, 14.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c2ada16a95e4bf896ec896e78ff2a2c"
          }
        },
        "59acb0938f52407dada7bb24c2efd584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8568d678beea41e2aad641b694e5db5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "225b67535a4a4792ad5b60baf3d91ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c2ada16a95e4bf896ec896e78ff2a2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a8ffa0d6c494e76b8b74b8246f22f4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_578ce3066ea144449b8b453eb87097a0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dc0204ddbab6494190c7ae263044889e",
              "IPY_MODEL_cabb11ef126049c4bfdbe83ed51149eb"
            ]
          }
        },
        "578ce3066ea144449b8b453eb87097a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc0204ddbab6494190c7ae263044889e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_baee736082174db6b7677c924e536970",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_80373cccbd2a447aa7871b91a9b32e6a"
          }
        },
        "cabb11ef126049c4bfdbe83ed51149eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a95edf1a2a6e411f9eea515a1fb12b67",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 440M/440M [00:05&lt;00:00, 73.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac9836794e2a41188f58bd941a521433"
          }
        },
        "baee736082174db6b7677c924e536970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "80373cccbd2a447aa7871b91a9b32e6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a95edf1a2a6e411f9eea515a1fb12b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac9836794e2a41188f58bd941a521433": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oaarnikoivu/dissertation/blob/master/Attention_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWaTkjkKu9TB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "5a812e96-6163-476c-b246-eee452d20fa3"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 26.4MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 51.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 52.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 53.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=4b291c818e88c02939ff9ac45857c4e3aa7e2095d4c5eb323d633111638ff30d\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy40NOL-vFij",
        "colab_type": "code",
        "outputId": "efffaf7d-8100-4385-9728-c5a3be84ed0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLFhbGO8C4gJ",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xU5Pc6mvbY0",
        "colab_type": "code",
        "outputId": "a8f020b8-d641-4650-aba4-5c811c14fa54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "import torch\n",
        "import random\n",
        "import transformers\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from pathlib import Path\n",
        "from torchtext import data\n",
        "from transformers import BertTokenizer, BertModel"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZYWV6HMDEm6",
        "colab_type": "text"
      },
      "source": [
        "# Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FczMGWp1vM_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = {\n",
        "    \"bert_tokenizer\": \"bert-base-uncased\",\n",
        "    \"bert_pretrained_model\": \"bert-base-uncased\",\n",
        "    \"seed\": 1234,\n",
        "    \"batch_size\": 64,\n",
        "    \"num_filters\": 100,\n",
        "    \"filter_sizes\": [3,4,5],\n",
        "    \"output_dim\": 11,\n",
        "    \"hidden_size\": 768,\n",
        "    \"num_layers\": 2,\n",
        "    \"dropout\": 0.5,\n",
        "    \"fc_dropout\": 0.5,\n",
        "    \"embed_dropout\": 0.2,\n",
        "    \"epochs\": 10\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QizRI-q1DPf1",
        "colab_type": "text"
      },
      "source": [
        "# Setup Bert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4nYNxu4vV9X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "b4c51af6063f4c4b867b7a713b38772f",
            "d1e43ff4ec8441c5b09f2b97f652106b",
            "048f57ad1e2541789b83a068165a57b4",
            "2ba4ef0a49d145a4bc810bf5fae01773",
            "42cc66053ab340c08d3f5bf8e66de995",
            "b7c98f00deba43848260ef642eef5939",
            "3da62a4916c5401f86ce26fce908cf0a",
            "f7425d7bafd0453f93eca7d1cfc49fa3"
          ]
        },
        "outputId": "176e1539-f6ac-40cc-c2ea-ae0f311952bb"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(args['bert_tokenizer'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4c51af6063f4c4b867b7a713b38772f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqDxLYBQvYc-",
        "colab_type": "code",
        "outputId": "24e9f323-e206-42b8-d943-6ee6b4b22cdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "init_token = tokenizer.cls_token\n",
        "eos_token = tokenizer.sep_token\n",
        "pad_token = tokenizer.pad_token\n",
        "unk_token = tokenizer.unk_token\n",
        "\n",
        "print(init_token, eos_token, pad_token, unk_token)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] [SEP] [PAD] [UNK]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDPOUfFuvjvy",
        "colab_type": "code",
        "outputId": "6b53fb88-3989-4f87-af53-75bb6f435d8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "init_token_idx = tokenizer.cls_token_id\n",
        "eos_token_idx = tokenizer.sep_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101 102 0 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBv0eC2xvss-",
        "colab_type": "code",
        "outputId": "e8061f45-d728-4085-ad05-d0372bff0b37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes[args['bert_tokenizer']]\n",
        "\n",
        "print(max_input_length)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMBjmcymvlY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_and_cut(tweet):\n",
        "  tokens = tokenizer.tokenize(tweet)\n",
        "  tokens = tokens[:max_input_length-2]\n",
        "  return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFFnMbqQDbJC",
        "colab_type": "text"
      },
      "source": [
        "# Load and Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYj3qsDpvmwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = '/content/drive/My Drive'\n",
        "\n",
        "DATA_PATH = Path(file_path + '/datasets/SemEval')\n",
        "\n",
        "random.seed(args['seed'])\n",
        "np.random.seed(args['seed'])\n",
        "torch.manual_seed(args['seed'])\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(batch_first = True,\n",
        "                  use_vocab = False,\n",
        "                  tokenize = tokenize_and_cut,\n",
        "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                  init_token = init_token_idx,\n",
        "                  eos_token = eos_token_idx,\n",
        "                  pad_token = pad_token_idx,\n",
        "                  unk_token = unk_token_idx)\n",
        "\n",
        "LABEL = data.LabelField(sequential = False,\n",
        "                        use_vocab = False,\n",
        "                        pad_token= None,\n",
        "                        unk_token = None, \n",
        "                        dtype = torch.float)\n",
        "\n",
        "dataFields = {\"Tweet\": (\"Tweet\", TEXT),\n",
        "              'anger': (\"anger\", LABEL),\n",
        "              'anticipation': (\"anticipation\", LABEL),\n",
        "              'disgust': (\"disgust\", LABEL),\n",
        "              'fear': (\"fear\", LABEL),\n",
        "              'joy': (\"joy\", LABEL),\n",
        "              'love': (\"love\", LABEL),\n",
        "              'optimism': (\"optimism\", LABEL),\n",
        "              'pessimism': (\"pessimism\", LABEL),\n",
        "              'sadness': (\"sadness\", LABEL),\n",
        "              'surprise': (\"surprise\", LABEL),\n",
        "              'trust': (\"trust\", LABEL)}\n",
        "\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "    path = DATA_PATH,\n",
        "    train = 'train.csv',\n",
        "    validation = 'val.csv',\n",
        "    test = 'test.csv',\n",
        "    format = 'csv',\n",
        "    fields = dataFields\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYMezWxUvyxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    sort_key = lambda x: len(x.Tweet),\n",
        "    sort_within_batch = True,\n",
        "    batch_size = args['batch_size'],\n",
        "    device = device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dgYzwnpDhrO",
        "colab_type": "text"
      },
      "source": [
        "# Batch Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEZCExSovoy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLS = ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
        "              'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']\n",
        "\n",
        "iaux = 0\n",
        "\n",
        "for batch in valid_iterator:\n",
        "  iaux += 1\n",
        "  aux = batch\n",
        "  aux2 = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "  if aux == 20: break;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyMA1ST4DlLN",
        "colab_type": "text"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77GLQlKxDnAx",
        "colab_type": "text"
      },
      "source": [
        "Load the pretrained bert model from the HuggingFace transformers library.\n",
        "\n",
        "https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRiJ1llOvvxz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "e6e23166515c464895fa280dd65539b5",
            "7e5b6c665247469e8d4112c43680516b",
            "a07f1b4fe8ac42a295316580c93d72a9",
            "5301a0a051d5473b858e8971f444968c",
            "59acb0938f52407dada7bb24c2efd584",
            "8568d678beea41e2aad641b694e5db5a",
            "225b67535a4a4792ad5b60baf3d91ef6",
            "9c2ada16a95e4bf896ec896e78ff2a2c",
            "7a8ffa0d6c494e76b8b74b8246f22f4f",
            "578ce3066ea144449b8b453eb87097a0",
            "dc0204ddbab6494190c7ae263044889e",
            "cabb11ef126049c4bfdbe83ed51149eb",
            "baee736082174db6b7677c924e536970",
            "80373cccbd2a447aa7871b91a9b32e6a",
            "a95edf1a2a6e411f9eea515a1fb12b67",
            "ac9836794e2a41188f58bd941a521433"
          ]
        },
        "outputId": "22ee19ad-6fbf-4ae0-f5ab-58297abf5979"
      },
      "source": [
        "bert = BertModel.from_pretrained(args['bert_pretrained_model'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6e23166515c464895fa280dd65539b5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a8ffa0d6c494e76b8b74b8246f22f4f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD1MiUiwv29n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, hidden_size):\n",
        "    super(Attention, self).__init__()\n",
        "    self.attention = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.tanh(x)\n",
        "    x = self.attention(x).squeeze(2)\n",
        "    alpha = F.softmax(x, dim=1).unsqueeze(1)\n",
        "    return alpha\n",
        "\n",
        "class AttentionBiLSTM(nn.Module):\n",
        "  def __init__(self, bert, hidden_size, num_layers, dropout, fc_dropout, \n",
        "               embed_dropout, num_classes):\n",
        "    super(AttentionBiLSTM, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size \n",
        "    self.bert = bert \n",
        "    embedding_dim = 768 \n",
        "\n",
        "    self.embed_dropout = nn.Dropout(embed_dropout)\n",
        "\n",
        "    self.bilstm = nn.LSTM(embedding_dim, \n",
        "                          hidden_size, \n",
        "                          num_layers, \n",
        "                          dropout=(0 if num_layers==1 else dropout),\n",
        "                          bidirectional=True,\n",
        "                          batch_first=True)\n",
        "    \n",
        "    self.fc = nn.Linear(hidden_size, num_classes)\n",
        "    self.fc_dropout = nn.Dropout(fc_dropout)\n",
        "    \n",
        "    self.attention = Attention(hidden_size)\n",
        "  \n",
        "  def forward(self, text):\n",
        "    with torch.no_grad():\n",
        "      x = self.bert(text)[0]\n",
        "    \n",
        "    x = self.embed_dropout(x)\n",
        "    y, _ = self.bilstm(x)\n",
        "    y = y[:,:,:self.hidden_size] + y[:,:,self.hidden_size:]\n",
        "    alpha = self.attention(y)\n",
        "    r = alpha.bmm(y).squeeze(1)\n",
        "    h = torch.tanh(r)\n",
        "    logits = self.fc(h)\n",
        "    logits = self.fc_dropout(logits)\n",
        "    return logits, alpha "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukvWtx9gxE1d",
        "colab_type": "code",
        "outputId": "1d2d64c9-29c2-4a60-bb7f-090727d49fad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = AttentionBiLSTM(\n",
        "    bert=bert,\n",
        "    hidden_size=args['hidden_size'],\n",
        "    num_layers=args['num_layers'],\n",
        "    dropout=args['dropout'],\n",
        "    fc_dropout=args['fc_dropout'],\n",
        "    embed_dropout=args['embed_dropout'],\n",
        "    num_classes=args['output_dim'],\n",
        ")\n",
        "\n",
        "model"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AttentionBiLSTM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (embed_dropout): Dropout(p=0.2, inplace=False)\n",
              "  (bilstm): LSTM(768, 768, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "  (fc): Linear(in_features=768, out_features=11, bias=True)\n",
              "  (fc_dropout): Dropout(p=0.5, inplace=False)\n",
              "  (attention): Attention(\n",
              "    (attention): Linear(in_features=768, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HIm_dK8EbZ2",
        "colab_type": "text"
      },
      "source": [
        "Freeze the parameters which are a part of the Bert Transformers model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4i0FWYtxQ0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if name.startswith('bert'):\n",
        "        param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC9ZocNzEoDZ",
        "colab_type": "text"
      },
      "source": [
        "Show the trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1af7wW5xYk_",
        "colab_type": "code",
        "outputId": "5df6ff34-d5b7-4a16-964a-076dd4adc73c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bilstm.weight_ih_l0\n",
            "bilstm.weight_hh_l0\n",
            "bilstm.bias_ih_l0\n",
            "bilstm.bias_hh_l0\n",
            "bilstm.weight_ih_l0_reverse\n",
            "bilstm.weight_hh_l0_reverse\n",
            "bilstm.bias_ih_l0_reverse\n",
            "bilstm.bias_hh_l0_reverse\n",
            "bilstm.weight_ih_l1\n",
            "bilstm.weight_hh_l1\n",
            "bilstm.bias_ih_l1\n",
            "bilstm.bias_hh_l1\n",
            "bilstm.weight_ih_l1_reverse\n",
            "bilstm.weight_hh_l1_reverse\n",
            "bilstm.bias_ih_l1_reverse\n",
            "bilstm.bias_hh_l1_reverse\n",
            "fc.weight\n",
            "fc.bias\n",
            "attention.attention.weight\n",
            "attention.attention.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLuzW7f4EyrX",
        "colab_type": "text"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1CpxbIDxcb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwZIAAQmxfxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amV2jA0oE2Rx",
        "colab_type": "text"
      },
      "source": [
        "We evaluate using the ROC AUC score and the macro and micro F1's as there are more suitable for multi-label text classification problems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxF1sRahxmwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score, jaccard_similarity_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YydgwAqkxolz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metricize(preds, y):\n",
        "  f1_macro = f1_score(y, preds.round(), average='macro')\n",
        "  f1_micro = f1_score(y, preds.round(), average='micro')\n",
        "  #acc = roc_auc_score(y, preds)\n",
        "  acc = jaccard_similarity_score(y, preds.round())\n",
        "\n",
        "  return {\n",
        "      'f1_macro': f1_macro,\n",
        "      'f1_micro': f1_micro,\n",
        "      'acc': acc\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLL3mSPZxpkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  for i, batch in enumerate(iterator):\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    predictions, _ = model(batch.Tweet)\n",
        "\n",
        "    batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "    batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "    loss = criterion(predictions, batch_labels)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "    labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "  \n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoLaQBVvxrla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    for batch in iterator:\n",
        "\n",
        "      predictions, _ = model(batch.Tweet)\n",
        "\n",
        "      batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "      batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "      loss = criterion(predictions, batch_labels)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "      labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO9vUx_1xtXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqaePMLEFP7e",
        "colab_type": "text"
      },
      "source": [
        "We train the model for 10 epochs and record the training and validation loss. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSBSFoBOxwJn",
        "colab_type": "code",
        "outputId": "97ae99d9-ac85-4826-bd63-19582ac6fe0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_history = []\n",
        "valid_history = []\n",
        "\n",
        "for epoch in range(args['epochs']):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_metrics = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_metrics = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    train_history.append(train_loss)\n",
        "    valid_history.append(valid_loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'bert-lstm-model.pt')\n",
        "\n",
        "    train_acc = train_metrics['acc']\n",
        "    train_micro = train_metrics['f1_micro']\n",
        "    train_macro = train_metrics['f1_macro']\n",
        "\n",
        "    valid_acc = valid_metrics['acc']\n",
        "    valid_micro = valid_metrics['f1_micro']\n",
        "    valid_macro = valid_metrics['f1_macro']\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Train F1 Micro: {train_micro*100:.2f}% | Train F1 Macro: {train_macro*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%  | Val. F1 Micro: {valid_micro*100:.2f}%  | Val. F1 Macro: {valid_macro*100:.2f}%')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 26s\n",
            "\tTrain Loss: 0.496 | Train Acc: 29.51% | Train F1 Micro: 41.95% | Train F1 Macro: 30.88%\n",
            "\t Val. Loss: 0.349 | Val. Acc: 54.99%  | Val. F1 Micro: 66.56%  | Val. F1 Macro: 52.42%\n",
            "Epoch: 02 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.494 | Train Acc: 30.71% | Train F1 Micro: 43.17% | Train F1 Macro: 32.87%\n",
            "\t Val. Loss: 0.356 | Val. Acc: 55.86%  | Val. F1 Micro: 67.70%  | Val. F1 Macro: 50.90%\n",
            "Epoch: 03 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.490 | Train Acc: 29.94% | Train F1 Micro: 42.71% | Train F1 Macro: 33.39%\n",
            "\t Val. Loss: 0.346 | Val. Acc: 55.00%  | Val. F1 Micro: 67.18%  | Val. F1 Macro: 52.53%\n",
            "Epoch: 04 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.485 | Train Acc: 30.93% | Train F1 Micro: 43.77% | Train F1 Macro: 34.00%\n",
            "\t Val. Loss: 0.342 | Val. Acc: 55.37%  | Val. F1 Micro: 67.16%  | Val. F1 Macro: 49.73%\n",
            "Epoch: 05 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.481 | Train Acc: 31.85% | Train F1 Micro: 44.60% | Train F1 Macro: 35.99%\n",
            "\t Val. Loss: 0.334 | Val. Acc: 55.29%  | Val. F1 Micro: 67.33%  | Val. F1 Macro: 51.60%\n",
            "Epoch: 06 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.475 | Train Acc: 33.66% | Train F1 Micro: 46.74% | Train F1 Macro: 37.39%\n",
            "\t Val. Loss: 0.337 | Val. Acc: 57.34%  | Val. F1 Micro: 68.62%  | Val. F1 Macro: 51.99%\n",
            "Epoch: 07 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.472 | Train Acc: 33.72% | Train F1 Micro: 47.39% | Train F1 Macro: 39.28%\n",
            "\t Val. Loss: 0.344 | Val. Acc: 56.67%  | Val. F1 Micro: 68.14%  | Val. F1 Macro: 53.45%\n",
            "Epoch: 08 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.469 | Train Acc: 33.66% | Train F1 Micro: 47.36% | Train F1 Macro: 39.39%\n",
            "\t Val. Loss: 0.342 | Val. Acc: 55.84%  | Val. F1 Micro: 67.07%  | Val. F1 Macro: 51.34%\n",
            "Epoch: 09 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.462 | Train Acc: 34.92% | Train F1 Micro: 48.41% | Train F1 Macro: 40.38%\n",
            "\t Val. Loss: 0.344 | Val. Acc: 54.30%  | Val. F1 Micro: 65.78%  | Val. F1 Macro: 52.77%\n",
            "Epoch: 10 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.463 | Train Acc: 35.60% | Train F1 Micro: 49.12% | Train F1 Macro: 41.46%\n",
            "\t Val. Loss: 0.340 | Val. Acc: 55.76%  | Val. F1 Micro: 67.28%  | Val. F1 Macro: 52.48%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqXexw71GcWj",
        "colab_type": "text"
      },
      "source": [
        "# Visualize the training and validation loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CePfv7_0An7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgUKd4HR6Tg-",
        "colab_type": "code",
        "outputId": "6a5b8e2a-eff2-4fbd-a8b3-49ad47b47d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "plt.plot(train_history)\n",
        "plt.plot(valid_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Training', 'Validation'])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f11bd9d8a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEYlLASEiInEpIEREJK7/H8IILnp1v9OaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtOPAqB1GkB5",
        "colab_type": "text"
      },
      "source": [
        "# Assess model performance on testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TxQGreq6Vgm",
        "colab_type": "code",
        "outputId": "7b6c4ce4-25eb-4f09-abea-dd5dc7832ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "model.load_state_dict(torch.load('bert-lstm-model.pt'))\n",
        "\n",
        "test_loss, test_metrics = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "test_acc = test_metrics['acc']\n",
        "test_micro = test_metrics['f1_micro']\n",
        "test_macro = test_metrics['f1_macro']\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test F1 Micro: {test_micro*100:.2f}% | Test F1 Macro: {test_macro*100:.2f}%')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.333 | Test Acc: 54.93% | Test F1 Micro: 66.81% | Test F1 Macro: 50.56%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaJzLdwb6exr",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ6W1Xpq6aO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_emotion(model, tokenizer, tweet):\n",
        "  preds = []\n",
        "  model.eval()\n",
        "  tokens = tokenizer.tokenize(tweet)\n",
        "  tokens = tokens[:max_input_length-2]\n",
        "  indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  tensor = tensor.unsqueeze(0)\n",
        "  predictions, attn_weights = model(tensor)\n",
        "  preds.append(torch.sigmoid(predictions).detach().cpu().numpy())\n",
        "  return preds, attn_weights, tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL9EtxTrG7My",
        "colab_type": "text"
      },
      "source": [
        "Lets test the model on our own input and save the attention weights and tokens for visualization. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eecw3IVA6lVH",
        "colab_type": "code",
        "outputId": "2c0640f9-26a2-46d2-9436-90e9d8b61f4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "preds, attn_weights, tokens = predict_emotion(model, tokenizer, \n",
        "                                              \"The weather is terrible. Don't want to go outside.\")\n",
        "\n",
        "vals = []\n",
        "for p in preds[0]:\n",
        "  for val in p:\n",
        "    vals.append(val)\n",
        "\n",
        "for i, label in enumerate(LABEL_COLS):\n",
        "  print(f\"{label.upper()}: {vals[i]}\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ANGER: 0.6073824167251587\n",
            "ANTICIPATION: 0.1323329508304596\n",
            "DISGUST: 0.5998157262802124\n",
            "FEAR: 0.575534999370575\n",
            "JOY: 0.0709107369184494\n",
            "LOVE: 0.012199895456433296\n",
            "OPTIMISM: 0.03402947634458542\n",
            "PESSIMISM: 0.40288305282592773\n",
            "SADNESS: 0.683454155921936\n",
            "SURPRISE: 0.08781830221414566\n",
            "TRUST: 0.015108262188732624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jeDWh8KHbEG",
        "colab_type": "text"
      },
      "source": [
        "Here we format the attention weights and store the results in a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q71LaaAn6oBA",
        "colab_type": "code",
        "outputId": "d0ce01ed-7bfa-49ba-bce2-f02f6ade814f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "aws = []\n",
        "for a in attn_weights[0]:\n",
        "  for v in a:\n",
        "    aws.append(v.detach().cpu().numpy())\n",
        "\n",
        "aws = aws[1:-1]\n",
        "aws = np.array(aws)\n",
        "aws"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00916477, 0.08340563, 0.07549096, 0.6515933 , 0.01220551,\n",
              "       0.00905193, 0.00610724, 0.0195145 , 0.07537189, 0.02865048,\n",
              "       0.0138502 , 0.00612202, 0.0033385 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnrDFOGy9DLx",
        "colab_type": "code",
        "outputId": "8f4af340-214c-40ab-f919-de5256e8ffb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "attn_dict = {}\n",
        "for i in range(len(aws)):\n",
        "  attn_dict[tokens[i]] = aws[i]\n",
        "\n",
        "print(attn_dict)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 0.009164775, 'weather': 0.08340563, 'is': 0.07549096, 'terrible': 0.6515933, '.': 0.0033385048, 'don': 0.009051931, \"'\": 0.00610724, 't': 0.019514503, 'want': 0.07537189, 'to': 0.028650481, 'go': 0.013850196, 'outside': 0.0061220163}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tomju0TvHp8z",
        "colab_type": "text"
      },
      "source": [
        "Lets return the top 3 words that the model focused on. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skdcPb0g-nQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LqBqNKVCqan",
        "colab_type": "code",
        "outputId": "7ca19252-8e3d-4d04-c7d8-e43aff63c996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Counter(attn_dict).most_common(3)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('terrible', 0.6515933), ('weather', 0.08340563), ('is', 0.07549096)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEX55PJi2-PU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}