{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sem-Eval 2018 Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOoU5BXc54dtZBna3Up/T12",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oaarnikoivu/dissertation/blob/master/Sem_Eval_2018_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xwmqsjEUwr6",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH_mZxBwUjpS",
        "colab_type": "code",
        "outputId": "04e195da-ed23-45d8-bc47-f3c469e9ceee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import collections\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qRRCrEuU5yl",
        "colab_type": "code",
        "outputId": "5b748448-da62-4436-cc72-0fef2f9abc83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQOhU4RaVM1O",
        "colab_type": "text"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJO9yG8iVCyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(filename):\n",
        "  data = pd.read_csv(filename, sep='\\t')\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOmjgI-mVUwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = '/content/drive/My Drive/datasets/'\n",
        "\n",
        "train = load_data(file_path + '2018-E-c-En-train.txt')\n",
        "val = load_data(file_path + '2018-E-c-En-dev.txt')\n",
        "test = load_data(file_path + '2018-E-c-En-test-gold.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmGiIK61Vchi",
        "colab_type": "code",
        "outputId": "6888ebbf-d36f-4ee8-dfba-28015ae98f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>anger</th>\n",
              "      <th>anticipation</th>\n",
              "      <th>disgust</th>\n",
              "      <th>fear</th>\n",
              "      <th>joy</th>\n",
              "      <th>love</th>\n",
              "      <th>optimism</th>\n",
              "      <th>pessimism</th>\n",
              "      <th>sadness</th>\n",
              "      <th>surprise</th>\n",
              "      <th>trust</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-En-21441</td>\n",
              "      <td>“Worry is a down payment on a problem you may ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-En-31535</td>\n",
              "      <td>Whatever you decide to do make sure it makes y...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-En-21068</td>\n",
              "      <td>@Max_Kellerman  it also helps that the majorit...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-En-31436</td>\n",
              "      <td>Accept the challenges so that you can literall...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-En-22195</td>\n",
              "      <td>My roommate: it's okay that we can't spell bec...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              ID  ... trust\n",
              "0  2017-En-21441  ...     1\n",
              "1  2017-En-31535  ...     0\n",
              "2  2017-En-21068  ...     0\n",
              "3  2017-En-31436  ...     0\n",
              "4  2017-En-22195  ...     0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1bajijraPCm",
        "colab_type": "text"
      },
      "source": [
        "Lets create a list of all labels to predicts and also a 'none' label to see how many tweets have no labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqnugydRZ6fK",
        "colab_type": "code",
        "outputId": "1c1ca2bd-1134-49c0-b881-33b6f0a1f7a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "class_names = ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', \n",
        "              'optimism', 'pessimism', 'sadness', 'surprise', 'trust']\n",
        "\n",
        "train['none'] = 1-train[class_names].max(axis=1)\n",
        "train.describe()"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>anger</th>\n",
              "      <th>anticipation</th>\n",
              "      <th>disgust</th>\n",
              "      <th>fear</th>\n",
              "      <th>joy</th>\n",
              "      <th>love</th>\n",
              "      <th>optimism</th>\n",
              "      <th>pessimism</th>\n",
              "      <th>sadness</th>\n",
              "      <th>surprise</th>\n",
              "      <th>trust</th>\n",
              "      <th>none</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6838.000000</td>\n",
              "      <td>6838.000000</td>\n",
              "      <td>6838.000000</td>\n",
              "      <td>6838.000000</td>\n",
              "      <td>6838.000000</td>\n",
              "      <td>6838.000000</td>\n",
              "      <td>6838.000000</td>\n",
              "      <td>6838.000000</td>\n",
              "      <td>6838.000000</td>\n",
              "      <td>6838.000000</td>\n",
              "      <td>6838.000000</td>\n",
              "      <td>6838.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.372039</td>\n",
              "      <td>0.143024</td>\n",
              "      <td>0.380521</td>\n",
              "      <td>0.181632</td>\n",
              "      <td>0.362240</td>\n",
              "      <td>0.102369</td>\n",
              "      <td>0.290143</td>\n",
              "      <td>0.116262</td>\n",
              "      <td>0.293653</td>\n",
              "      <td>0.052793</td>\n",
              "      <td>0.052208</td>\n",
              "      <td>0.029833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.483384</td>\n",
              "      <td>0.350123</td>\n",
              "      <td>0.485550</td>\n",
              "      <td>0.385569</td>\n",
              "      <td>0.480683</td>\n",
              "      <td>0.303155</td>\n",
              "      <td>0.453862</td>\n",
              "      <td>0.320562</td>\n",
              "      <td>0.455468</td>\n",
              "      <td>0.223637</td>\n",
              "      <td>0.222463</td>\n",
              "      <td>0.170140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             anger  anticipation  ...        trust         none\n",
              "count  6838.000000   6838.000000  ...  6838.000000  6838.000000\n",
              "mean      0.372039      0.143024  ...     0.052208     0.029833\n",
              "std       0.483384      0.350123  ...     0.222463     0.170140\n",
              "min       0.000000      0.000000  ...     0.000000     0.000000\n",
              "25%       0.000000      0.000000  ...     0.000000     0.000000\n",
              "50%       0.000000      0.000000  ...     0.000000     0.000000\n",
              "75%       1.000000      0.000000  ...     0.000000     0.000000\n",
              "max       1.000000      1.000000  ...     1.000000     1.000000\n",
              "\n",
              "[8 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyeEDnTXaZRS",
        "colab_type": "code",
        "outputId": "57330448-9858-4746-a3b3-805de212f1bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train), len(test), len(val)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6838, 3259, 886)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJZyiv8oajAE",
        "colab_type": "text"
      },
      "source": [
        "Since there are a few empty tweets, we will replace these with: 'unknown'. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvSS2WpjaprC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['Tweet'].fillna(\"unknown\", inplace=True)\n",
        "test['Tweet'].fillna(\"unknown\", inplace=True)\n",
        "val['Tweet'].fillna(\"unknown\", inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01ECGMWCcDA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text = train['Tweet']\n",
        "test_text = test['Tweet']\n",
        "val_text = val['Tweet']\n",
        "all_text = pd.concat([train_text, test_text, val_text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkt3Zn7aWufB",
        "colab_type": "text"
      },
      "source": [
        "## Text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_2bkLGdV4kX",
        "colab_type": "code",
        "outputId": "9570be95-2e30-4d4f-de5f-8a218c8d573f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "train_text.head()"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    “Worry is a down payment on a problem you may ...\n",
              "1    Whatever you decide to do make sure it makes y...\n",
              "2    @Max_Kellerman  it also helps that the majorit...\n",
              "3    Accept the challenges so that you can literall...\n",
              "4    My roommate: it's okay that we can't spell bec...\n",
              "Name: Tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuka2cosW2u1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def preprocessor(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    #text = re.sub('#', '', text) # remove hashtags\n",
        "    text = REPLACE_BY_SPACE_RE.sub('', text)\n",
        "    text = BAD_SYMBOLS_RE.sub('', text)\n",
        "    text = ' '.join([word for word in text.split() if word not in STOPWORDS])\n",
        "    text = text.strip()\n",
        "  \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31047SavW8d4",
        "colab_type": "code",
        "outputId": "5de80cc8-16a8-476d-8e84-52276c4d657b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "preprocessor(train_text[250])"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dont #afraid space #dreams #reality #dream #make'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X_hSl1zX90L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text = train_text.apply(preprocessor)\n",
        "test_text = test_text.apply(preprocessor)\n",
        "val_text = val_text.apply(preprocessor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpuqwfXvc4_N",
        "colab_type": "code",
        "outputId": "940eed87-eac4-4dca-860d-a18aea1c5a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "train_text.head()"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    worry payment problem may never joyce meyer #m...\n",
              "1               whatever decide make sure makes #happy\n",
              "2    max_kellerman also helps majority nfl coaching...\n",
              "3    accept challenges literally even feel exhilara...\n",
              "4    roommate okay cant spell autocorrect #terrible...\n",
              "Name: Tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_W8UD69eD6N",
        "colab_type": "text"
      },
      "source": [
        "## Transforming text to a vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUYFy1IyekKI",
        "colab_type": "text"
      },
      "source": [
        "### TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inKaZBQieYwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYRQVv-Qf6YH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tfidf_features(train, val, test):\n",
        "  vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.9, min_df=2,\n",
        "                               token_pattern='(\\S+)')\n",
        "  \n",
        "  vectorizer.fit(all_text)\n",
        "\n",
        "  train_features = vectorizer.transform(train)\n",
        "  test_features = vectorizer.transform(test)\n",
        "  val_features = vectorizer.transform(val)\n",
        "\n",
        "  return vectorizer, train_features, val_features, test_features, vectorizer.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4reWcNvly7MM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vect, train_features, val_features, test_features, vocab = tfidf_features(train_text, val_text, test_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV0GctD3zMNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vocab['alcohol']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGQBpBDqnfdF",
        "colab_type": "text"
      },
      "source": [
        "## Train classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCcnK49InfJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR2xeCE-nY6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_classifier(X_train, X_val, X_test, pred_text):\n",
        "\n",
        "  clf = OneVsRestClassifier(LogisticRegression())\n",
        "\n",
        "  predictions = []\n",
        "  scores = []\n",
        "\n",
        "  for class_name in class_names:\n",
        "    print('\\n... Processing {}'.format(class_name))\n",
        "\n",
        "    train_target = train[class_name]\n",
        "    test_target = test[class_name]\n",
        "    val_target = val[class_name]\n",
        "\n",
        "    cv_score = np.mean(cross_val_score(clf, train_features, train_target, cv=3, scoring='roc_auc'))\n",
        "    scores.append(cv_score)\n",
        "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
        "\n",
        "    clf.fit(X_train, train_target)\n",
        "\n",
        "    # compute training accuracy\n",
        "    y_pred_X_train = clf.predict(X_train)\n",
        "    print('Training accuracy is {}'.format(accuracy_score(train_target, y_pred_X_train)))\n",
        "    \n",
        "    # compute validation accuracy\n",
        "    y_pred_X_val = clf.predict(X_val)\n",
        "    print('Validation accuracy is {}'.format(accuracy_score(val_target, y_pred_X_val)))\n",
        "\n",
        "    # compute testing accuracy\n",
        "    y_pred_X_test = clf.predict(X_test)\n",
        "    print('Testing accuracy is {}'.format(accuracy_score(test_target, y_pred_X_test)))\n",
        "\n",
        "    for t in pred_text:\n",
        "      pred = clf.predict(vect.transform([t]))\n",
        "      if pred:\n",
        "        predictions.append(\"\\n\" + t + \"\\nPrediction: \" + class_name)\n",
        "\n",
        "  return (clf, predictions, scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf0hvJ4SoU4z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dfc8bf11-7dee-4f40-b7be-4a41b2274f1a"
      },
      "source": [
        "depressive_text = [\"I kind of understand what you mean. I guess we are depressed so much it becomes familiar, almost comfortable in a way. I get it.\",\n",
        "                   \"I thought I was the only one like this, I hate being this sad and all like one hurt myself and I wanna commit suicide but then again I wanna stay like this\",\n",
        "                   \"I can’t stand it anymore. I’m committing suicide. This is my story. Being good and positive won’t help u stop suffering.\",\n",
        "                   \"I'm sick of getting told life is always worth it and suicide isn't the answer.\",\n",
        "                   \"Do you ever feel like listening to sad music and crying for no apparent reason?\"]\n",
        "\n",
        "happy_text = [\"Just wanted to share my 6 month progress pic and how happy I am about it! I can't stop smiling everytime I see myself in the mirror. That's 60lbs of fat gone! For anyone out there struggling with self-esteem, you're beautiful. Don't ever let anyone tell you differently.\",\n",
        "              \"After years of being fat and unhealthy i’m so happy to be closer to my goal.\"]\n",
        "\n",
        "pred_text = depressive_text + happy_text\n",
        "\n",
        "(clf, preds, scores) = train_classifier(train_features, val_features, test_features, pred_text)\n",
        "\n",
        "print('\\nTotal CV score is {}'.format(np.mean(scores)))"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "... Processing anger\n",
            "CV score for class anger is 0.8552042250067343\n",
            "Training accuracy is 0.8601930389002632\n",
            "Validation accuracy is 0.7652370203160271\n",
            "Testing accuracy is 0.7714022706351642\n",
            "\n",
            "... Processing anticipation\n",
            "CV score for class anticipation is 0.675491604157343\n",
            "Training accuracy is 0.8613629716291313\n",
            "Validation accuracy is 0.8566591422121896\n",
            "Testing accuracy is 0.869898741945382\n",
            "\n",
            "... Processing disgust\n",
            "CV score for class disgust is 0.8110700291480288\n",
            "Training accuracy is 0.8331383445451886\n",
            "Validation accuracy is 0.7133182844243793\n",
            "Testing accuracy is 0.7480822338140534\n",
            "\n",
            "... Processing fear\n",
            "CV score for class fear is 0.8699509994718566\n",
            "Training accuracy is 0.8929511553085697\n",
            "Validation accuracy is 0.8927765237020316\n",
            "Testing accuracy is 0.8895366676894753\n",
            "\n",
            "... Processing joy\n",
            "CV score for class joy is 0.8649699547791666\n",
            "Training accuracy is 0.8606317636735887\n",
            "Validation accuracy is 0.7268623024830699\n",
            "Testing accuracy is 0.7526848726603252\n",
            "\n",
            "... Processing love\n",
            "CV score for class love is 0.8486796858491444\n",
            "Training accuracy is 0.9138637028370868\n",
            "Validation accuracy is 0.8758465011286681\n",
            "Testing accuracy is 0.8656029456888616\n",
            "\n",
            "... Processing optimism\n",
            "CV score for class optimism is 0.7953411529585356\n",
            "Training accuracy is 0.8173442527054694\n",
            "Validation accuracy is 0.7370203160270881\n",
            "Testing accuracy is 0.7220006136851795\n",
            "\n",
            "... Processing pessimism\n",
            "CV score for class pessimism is 0.6910483132887894\n",
            "Training accuracy is 0.8875402164375549\n",
            "Validation accuracy is 0.8860045146726863\n",
            "Testing accuracy is 0.8864682417919607\n",
            "\n",
            "... Processing sadness\n",
            "CV score for class sadness is 0.765038849841814\n",
            "Training accuracy is 0.8144194208832992\n",
            "Validation accuracy is 0.7641083521444695\n",
            "Testing accuracy is 0.7695612150966554\n",
            "\n",
            "... Processing surprise\n",
            "CV score for class surprise is 0.7406314396650832\n",
            "Training accuracy is 0.9498391342497806\n",
            "Validation accuracy is 0.9616252821670429\n",
            "Testing accuracy is 0.9493709726910096\n",
            "\n",
            "... Processing trust\n",
            "CV score for class trust is 0.6707922589228675\n",
            "Training accuracy is 0.9477917519742615\n",
            "Validation accuracy is 0.9514672686230248\n",
            "Testing accuracy is 0.953053083768027\n",
            "\n",
            "Total CV score is 0.7807471375535786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fUTwioP9RZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "c8577b65-9f91-40a4-bdae-de5d9776bde5"
      },
      "source": [
        "for p in preds:\n",
        "  print(p)"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "I'm sick of getting told life is always worth it and suicide isn't the answer.\n",
            "Prediction: anger\n",
            "\n",
            "After years of being fat and unhealthy i’m so happy to be closer to my goal.\n",
            "Prediction: joy\n",
            "\n",
            "Do you ever feel like listening to sad music and crying for no apparent reason?\n",
            "Prediction: sadness\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWMmwrwaR6D5",
        "colab_type": "text"
      },
      "source": [
        "# Word embeddings (GloVe) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFPHx6jALvgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}